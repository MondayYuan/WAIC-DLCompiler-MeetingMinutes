## 分组讨论环节问题和结论整理

> 1.合理的软硬件接口抽象是什么？

Rammer V2是一种尝试，即以tensor primitive作为接口，对硬件来说只要实现这些的primitve，而对软件来说做白盒编译，将tuning问题转化成task调度问题



> 2.王敏捷：算子的概念有意义吗?为什么有算子这个层次？

岚松：我也不支持，XLA 里面其实一直就是200多条规则，这么长时间基本上就没增加过；算子是易用性引入的，不是高效计算引入的。一定是先打散了再优化。对于编程人员是个好东西。

敏捷：是不是大家都应该move到 xla 这个层次上？

高洋、欣然：算子是研究员的一个领域概念

雪峰：是一个 mental model，帮助研究员之间方便来进行沟通；编译阶段确实好像不是很必要；算子某种意义上就是一个对 kernel 的annotation；有的时候也碰到 xla 拼不出来的情况。

鲍翀：算子是为了让算法工程化简化。

算子是提供了一个良好的量化的边界。

算子作为一个 program 概念合理，但是在优化层面上可能不太合适，有没有可能做一个良好的 IR 作为中间表示？是否存在算子以下更统一的IR表示？感觉有点难。



> 3.稀疏化如何支持？

尹首一：过去几年AI芯片的收益几乎都是来自于sparsity，很多顶级工作focus on input的动态稀疏。

硬件支持很难，结构化的稀疏先做；编译器方面可以提供更多支持。



> 4.大模型怎么用？

林达华：大模型资源趋向集中，形成马太效应，长期而言，可能会抑制整个领域的创新能力。

薛继龙：采用类似区块链的分布式或者联邦学习的方法，组成去中心化的算力网络，用户以类似挖矿的方式参与大模型训练，最后得到训练后的模型作为回报。



> 5.动态shape的价值有多大？如何支持？

一定要支持



> 6. runtime和compiler如何更合理的分工？

从芯片角度考虑怎么和driver配合，在颗粒度上做trade off



> 7. 软硬人员背景不同，二者如何协同？

软件栈也有希望聚合成类似RISC V的生态



> 8.不同大模型适合的切分策略不同，讨论需要更多workload背景的人参与 



> 9.如何形成行业内的共识？

组成小committee，定期进行讨论总结



> 10.训练场景下对性能提升的需要大吗?

open



> 11.雪峰：整个深度学习的 workload 是收敛的还是发散的？

敏捷：业务上大概率会继续收敛下去，但是 research 估计会继续花式
岚松：举个例子，业务上的模型都是卡在 IO 上，但是 research 的模型都是卡在很后边
雪峰：大规模商用的还是很收敛的，绝大多数模型都是很收敛的。

现在前后处理部分都还没入图呢，这块都还没搞定呢

岚松：之前看过一个挺成熟的框架，当时也是各种缺算子；业务模型写的五花八门
雪峰：很多芯片是算子提供的不够

高洋：移动端遇到抖音这样的厂商，要求库集成进去要能在所有的手机上跑起来，几乎没法做；以现在的深度学习编译器似乎解决不了
欣然：binary 大小、初始化时间等等也会成为严重的瓶颈
高洋：比如两款芯片的 DDR不一样，可能性能就不一样；所有手机上都用32bit 指令；
欣然：在这种需要支持大量平台的情况下，编译器方案就会非常局限



> 12. MLPerf是否代表了workload的收敛?

workload的收敛要看backbone是否趋同；而MLPerf更多是代表了玩家的利益。



> 13. conv/matmul之外的长尾算子如何优化？

取决于不规则算子的应用场景：research or 生产场景？



> 14. 如何达到算子表达能力的图灵完备性？

1. ONNX是否成功（tensorflow和pytorch都不待见onnx，但是硬件公司会支持ONNX，更多是商业问题而不是技术问题）；

2. Jittor的元算子；
3. 没有必要形成算子List协议（但是可以考虑如何加速这个过程，以DLPack为例，其成功原因在于：1.接口简单 2.后续迭代增加feature）；
4. 完备支持需要大量人力



> 15.岚松：如何构建更好的编译器生态？

岚松：为什么一个一个 pass 的方案不是最优的，但是存活下来了？因为这是让更多人能参与进来的内容；MLIR 是一个好的起点，大家可以各自做独立的事情；这是不是最好的方案？
敏捷：是不是一定是一个直线的 pipeline？
岚松：比如 crush cabin 可以做上下层的透传
敏捷：optimization 不能太早，太早了容易让 debug 太难了，这有什么实际上的做法习惯么？
岚松：编译器有很多的 option，所以大家往往就要试各种各样的 option；
鲍翀：AI 芯片上做了很多的 option，但是就在讨论这些 option 能不能开出来？
敏捷：gcc 里面有 O2，O3，我们有没有可能达成一个共识，形成一个标准
岚松：比如 DCE 肯定可以随意开，但是有很多不一定的（尤其是跟硬件相关的），这一点评估起来很困难；比如用一个网络给一个大概的方向，然后再 fine-tune option
欣然：有些公司内部会用 AI for system 的思路去 tune option
雪峰：gcc 之所以生态很好了，是因为底层的 ISA 是乱七八糟的，所以大家就做的很好
MLIR 一个是多层（这是llvm 的缺点，业界的好的编译器都是多层的（但一般都是固定的层数）），它不是个标准，所以大家每个人写的层数不一样，可能就很难互通
llvm 成功是来自于底层硬件已经很稳定了
现在编译器想要生态搞好了，多层 IR 一定要定好；一定要 ISA 稳定；

岚松：减少专用的硬件，尽量通过编译的方式来提高硬件复用率，需要和硬件工程师对话，控制多样性的冲动，要更标准化
敏捷：因为没用的专有硬件没用，所以芯片就不够行，然后就淘汰了这种芯片了，可能慢慢的就好了？
岚松：比如 input / output buffer 做死了，就不如做成能灵活腾挪的？
岚松：得看是不是 model 会慢慢收敛，如果一直不收敛性，那么硬件可能就一直在震荡了



> 16.雪峰：编程接口上能不能统一？为啥在 AI 领域有这么多语言，听起来一个 numpy + grad 接口就够了？在学术场景里基本上都已经是 numpy 了

敏捷：对于 R 来说最通用的语言是 Math，但是对于 Engineer 这块感觉各种难以统一
敏捷：总会遇到算子层面的问题吧
欣然：在 numpy level 的东西上已经事实上统一了，但是在其他的事情上确实很不统一；就像 programming language 一样难以统一，属于 flavor
岚松：之前用 JAX 做前端的时候，有一个好；TF 里不管是什么都在 GPU 上算，效率可能就不够快；但是 Jax 实际上的胶水代码都在 CPU 上，这可能是个挺高效的工作
鲍翀：：但是这是个异构问题，有时候传输代价可能大？
岚松：往往是一头一尾
敏捷：之前很明显缺的一个东西是 nn.Module、预处理之类的东西
欣然：预处理和模型不靠在一起就很不科学

欣然：MegEngine 做了一套 Tensor Interpreter，相当于做了一套 VM bytecode



> 17.雪峰：ONNX or MLIR？

雪峰：Mindspore 自己搞了一套，因为等不及 ONNX；ONNX 是个壳子
欣然：ONNX 经常容易变成搞不定就彻底自己搞，MLIR 至少能让这个事情大家有 common 祖先，更有可能做到渐进性严禁，也许能避免 ONNX 这种 0/1 问题
欣然：目前 MegEngine 的 Graph 已经都是 MLIR dialet 作为 graph presentation 了
敏捷：听起来 ONNX 是个 centre 模式，MLIR 可以是个更分布式的方案



> 18.欣然：训练框架未来是个更动态的还是更静态的，即是不是解释执行

雪峰：如果是动态的话，硬件没法继续严禁，需要解决功耗等等；DSA 对于动态天生不友好
也许可以通过一些方案，让用户可以尽量无感的做
全静态的肯定也是有需要的，对于生产场景下，能快一倍是很有价值的，极致能效比。
欣然：比如你看 GPU 上，早起生态不够好，所以大家静态有收益，现在慢慢的生态好了就动态了；那未来会不会 DSA 上的训练框架也会慢慢的变成更动态了（更快了）
雪峰：PyTorch 在A100时代后，TensorCore 这么大，估计也会遇到问题
欣然：动态图的诉求肯定是很强的，5年后我们是不是只要搞研究就一定是 pytorch + GPU？
敏捷：本质上是 DSA 芯片未来如何在动态图上打败 GPU？
敏捷：AI 时代很重要的还是要看 customer，如何让 AI 下沉是很重要的

刁岚松：加速器的core不宜过大，否则workload各个维度可能并不能cover计算单元。

